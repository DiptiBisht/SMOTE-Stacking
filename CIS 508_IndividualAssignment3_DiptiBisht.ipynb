{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vecstack\n",
      "  Downloading vecstack-0.4.0.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from vecstack) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from vecstack) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from vecstack) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (1.1.0)\n",
      "Building wheels for collected packages: vecstack\n",
      "  Building wheel for vecstack (setup.py): started\n",
      "  Building wheel for vecstack (setup.py): finished with status 'done'\n",
      "  Created wheel for vecstack: filename=vecstack-0.4.0-py3-none-any.whl size=19864 sha256=4d7ca9b181f760b39e3bb0db556f2ba95888dde8e903fd50ed37ce32b861dc73\n",
      "  Stored in directory: c:\\users\\dipti\\appdata\\local\\pip\\cache\\wheels\\7e\\ee\\d6\\47cb94a403bc544de1433986e5530d6b0498021098fbe43aa1\n",
      "Successfully built vecstack\n",
      "Installing collected packages: vecstack\n",
      "Successfully installed vecstack-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfa4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.3/199.3 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.9.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5113e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score #works\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter #for Smote, \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b8d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65000, 596)\n",
      "(173836, 596)\n",
      "   CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
      "0                 2                 1               17               23   \n",
      "1                 5                 9                6                8   \n",
      "2                 4                 6                7               12   \n",
      "3                15                23                3                2   \n",
      "4                 4                 6                8               13   \n",
      "\n",
      "   CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
      "0               17               23               15               22   \n",
      "1                6                8                5                7   \n",
      "2                7               12                6               10   \n",
      "3                3                2                2                2   \n",
      "4                8               13                7               11   \n",
      "\n",
      "   CoverageField4A  CoverageField4B  ...  PropertyField38_N  \\\n",
      "0               16               22  ...                  1   \n",
      "1                5                8  ...                  1   \n",
      "2                7               11  ...                  1   \n",
      "3                3                2  ...                  1   \n",
      "4                7               13  ...                  1   \n",
      "\n",
      "   PropertyField38_Y  GeographicField63_   GeographicField63_N  \\\n",
      "0                  0                    0                    1   \n",
      "1                  0                    0                    1   \n",
      "2                  0                    0                    1   \n",
      "3                  0                    0                    1   \n",
      "4                  0                    0                    1   \n",
      "\n",
      "   GeographicField63_Y  GeographicField64_CA  GeographicField64_IL  \\\n",
      "0                    0                     1                     0   \n",
      "1                    0                     0                     0   \n",
      "2                    0                     0                     0   \n",
      "3                    0                     0                     0   \n",
      "4                    0                     0                     1   \n",
      "\n",
      "   GeographicField64_NJ  GeographicField64_TX  QuoteConversion_Flag  \n",
      "0                     0                     0                     0  \n",
      "1                     1                     0                     0  \n",
      "2                     1                     0                     0  \n",
      "3                     0                     1                     0  \n",
      "4                     0                     0                     0  \n",
      "\n",
      "[5 rows x 596 columns]\n"
     ]
    }
   ],
   "source": [
    "trainfile = r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 3\\RevisedHomesiteTrain1.csv'\n",
    "train_data = pd.read_csv(trainfile)\n",
    "\n",
    "#train_data = pd.read_csv(\"C:\\Users\\dipti\\Documents\\CIS508\\Assignment 3\\RevisedHomesiteTrain1.csv\")\n",
    "\n",
    "\n",
    "testfile = r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 3\\RevisedHomesiteTest1.csv'\n",
    "test_data = pd.read_csv(testfile)\n",
    "\n",
    "#test_data = pd.read_csv(\"C:\\Users\\dipti\\Documents\\CIS508\\Assignment 3\\RevisedHomesiteTest1.csv\")\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c70e9315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65000,)\n",
      "(173836,)\n"
     ]
    }
   ],
   "source": [
    "X_train=train_data.iloc[:, :-1]\n",
    "X_test=test_data.iloc[:, :-1]\n",
    "y_train=train_data.iloc[:,-1]\n",
    "y_test=test_data.iloc[:,-1]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4d88b",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7856a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________\n",
      "SMOTE\n",
      "\n",
      "Original dataset shape Counter({0: 52738, 1: 12262})\n",
      "Resampled dataset shape Counter({0: 52738, 1: 26369})\n"
     ]
    }
   ],
   "source": [
    "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "sm = SMOTE(sampling_strategy=0.5)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c9bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size= 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d453ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for Decision Tree:0.880359\n",
      "Confusion Matrix for Decision Tree\n",
      "[[14631  1166]\n",
      " [ 1167  2536]]\n"
     ]
    }
   ],
   "source": [
    "#CONSTRUCT DEFAULT DECISION TREE AND OBTAIN RESPECTIVE ACCURACY \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "dt_predict=dt.predict(X_test)\n",
    "print(\"accuracy Score (training) for Decision Tree:{0:6f}\".format(dt.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for Decision Tree\")\n",
    "print(confusion_matrix(y_test, dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023b8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 10, 'max_depth': 9}\n",
      "accuracy Score (training) after hypertuning for Decision Tree:0.911590\n",
      "Confusion Matrix after hypertuning for Decision Tree\n",
      "[[15549   248]\n",
      " [ 1476  2227]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95     15797\n",
      "           1       0.90      0.60      0.72      3703\n",
      "\n",
      "    accuracy                           0.91     19500\n",
      "   macro avg       0.91      0.79      0.83     19500\n",
      "weighted avg       0.91      0.91      0.90     19500\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.816992   0.81590189 0.81589462 0.81211196 0.81141432 0.82028953\n",
      " 0.81536047 0.80866453 0.81994071 0.80781204]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Decision Tree:  0.8144382080308523\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for decision tree classifier\n",
    "parameters={'min_samples_split' : range(10,100,10),'max_depth': range(1,20,2)}\n",
    "dt_random = RandomizedSearchCV(dt, parameters, n_iter=15)\n",
    "dt_random.fit(X_train, y_train)\n",
    "grid_parm=dt_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier \n",
    "dt = DecisionTreeClassifier(**grid_parm)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_predict = dt.predict(X_test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for Decision Tree:{0:6f}\".format(dt.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for Decision Tree\")\n",
    "print(confusion_matrix(y_test,dt_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,dt_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "dt_cv_score = cross_val_score(df, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(dt_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Decision Tree: \",dt_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e708114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for RandomForest:0.903385\n",
      "Confusion Matrix for Random Forest:\n",
      "[[15590   207]\n",
      " [ 1677  2026]]\n"
     ]
    }
   ],
   "source": [
    "#Construct Random Forest Model\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predict=rfc.predict(X_test)\n",
    "print(\"accuracy Score (training) for RandomForest:{0:6f}\".format(rfc.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(confusion_matrix(y_test,rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ef79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 50, 'max_depth': 19}\n",
      "accuracy Score (training) after hypertuning for Random Forest:0.902718\n",
      "Confusion Matrix after hypertuning for Random Forest:\n",
      "[[15610   187]\n",
      " [ 1710  1993]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     15797\n",
      "           1       0.91      0.54      0.68      3703\n",
      "\n",
      "    accuracy                           0.90     19500\n",
      "   macro avg       0.91      0.76      0.81     19500\n",
      "weighted avg       0.90      0.90      0.89     19500\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.95342125 0.94774015 0.94034593 0.94747134 0.9431947  0.94832299\n",
      " 0.94876068 0.94444989 0.94681196 0.94620263]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.9466721505087559\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning for random forest classifier\n",
    "rfc_random = RandomizedSearchCV(rfc,parameters,n_iter=15)\n",
    "rfc_random.fit(X_train, y_train)\n",
    "grid_parm_rfc=rfc_random.best_params_\n",
    "print(grid_parm_rfc)\n",
    "\n",
    "#Construct Random Forest with best parameters\n",
    "rfc= RandomForestClassifier(**grid_parm_rfc)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "print(\"accuracy Score (training) after hypertuning for Random Forest:{0:6f}\".format(rfc.score(X_test, y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for Random Forest:\")\n",
    "print(confusion_matrix(y_test,rfc_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,rfc_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "rfc_cv_score = cross_val_score(rfc, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \",rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b671c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for MultiLayer Perceptron:0.761385\n",
      "Confusion Matrix for MultiLayer Perceptron:\n",
      "[[11865  3932]\n",
      " [  721  2982]]\n"
     ]
    }
   ],
   "source": [
    "#Construct MultiLayer Perceptron Model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_predict=mlp.predict(X_test)\n",
    "print(\"accuracy Score (training) for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for MultiLayer Perceptron:\")\n",
    "print(confusion_matrix(y_test,mlp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c74450b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 100, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10, 5, 3), 'activation': 'relu'}\n",
      "accuracy Score (training) after hypertuning for MultiLayer Perceptron:0.810103\n",
      "Confusion Matrix after hypertuning for MultiLayer Perceptron\n",
      "[[15797     0]\n",
      " [ 3703     0]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90     15797\n",
      "           1       0.00      0.00      0.00      3703\n",
      "\n",
      "    accuracy                           0.81     19500\n",
      "   macro avg       0.41      0.50      0.45     19500\n",
      "weighted avg       0.66      0.81      0.73     19500\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.5        0.50054142 0.50094748 0.5        0.87384126 0.52298673\n",
      " 0.5        0.5        0.5        0.85389518]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - MultiLayer Perceptron:  0.5752212070475483\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for MultiLayer Perceptron classifier\n",
    "\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (20,)], 'activation':['tanh', 'relu'], 'solver':['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate':['constant', 'adaptive']}\n",
    "#parameters = {'hidden_layer_sizes':[(10,5), (20,5)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive']}\n",
    "parameters = {'hidden_layer_sizes':[(10,5,3), (20,7,3)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive'], 'max_iter' :[100, 150]}\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (15,), (10,5), (20,7,3)]}\n",
    "\n",
    "mlp_random = RandomizedSearchCV(mlp,parameters,n_iter=15)\n",
    "mlp_random.fit(X_train, y_train)\n",
    "grid_parm=mlp_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "mlp = MLPClassifier(**grid_parm)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_predict = mlp.predict(X_test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test,  y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for MultiLayer Perceptron\")\n",
    "print(confusion_matrix(y_test, mlp_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, mlp_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "mlp_cv_score = cross_val_score(mlp, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(mlp_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - MultiLayer Perceptron: \",mlp_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "219c4af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for KNeighborsClassifier:0.753692\n",
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[14292  1505]\n",
      " [ 3298   405]]\n"
     ]
    }
   ],
   "source": [
    "#Construct K-Nearest Neighbor Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "neigh.fit(X_train, y_train)\n",
    "neigh_predict=neigh.predict(X_test)\n",
    "print(\"accuracy Score (training) for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test, y_test)))\n",
    "print(\"Confusion Matrix for KNeighborsClassifier:\")\n",
    "print(confusion_matrix(y_test, neigh_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e9a9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'uniform', 'p': 1, 'n_neighbors': 11}\n",
      "accuracy Score (training) after hypertuning for KNeighborsClassifier:0.803385\n",
      "Confusion Matrix after hypertuning for KNeighborsClassifier\n",
      "[[15569   228]\n",
      " [ 3606    97]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89     15797\n",
      "           1       0.30      0.03      0.05      3703\n",
      "\n",
      "    accuracy                           0.80     19500\n",
      "   macro avg       0.56      0.51      0.47     19500\n",
      "weighted avg       0.71      0.80      0.73     19500\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.56505276 0.58231317 0.5636328  0.56978559 0.56973942 0.56409089\n",
      " 0.57719863 0.56482285 0.56666785 0.5677777 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - KNeighborsClassifier:  0.5691081654541607\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for K-Nearest Neighbor classifier\n",
    "\n",
    "parameters = {'n_neighbors':[3,5,7,9,11], 'weights':['uniform', 'distance'], 'p':[1,2]}\n",
    "\n",
    "\n",
    "neigh_random = RandomizedSearchCV(neigh,parameters,n_iter=15)\n",
    "neigh_random.fit(X_train, y_train)\n",
    "grid_parm=neigh_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "neigh = KNeighborsClassifier(**grid_parm)\n",
    "neigh.fit(X_train,y_train)\n",
    "neigh_predict = neigh.predict(X_test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for KNeighborsClassifier\")\n",
    "print(confusion_matrix(y_test,neigh_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,neigh_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "neigh_cv_score = cross_val_score(neigh, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(neigh_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - KNeighborsClassifier: \",neigh_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe7233ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for Linear SVM Classifier:0.760564\n",
      "Confusion Matrix for Linear SVM Classifier:\n",
      "[[14247  1550]\n",
      " [ 3119   584]]\n"
     ]
    }
   ],
   "source": [
    "#Construct Linear Support Vector Machine Model\n",
    "from sklearn.svm import LinearSVC \n",
    "linsvm = LinearSVC(max_iter=300) \n",
    "linsvm.fit(X_train, y_train) \n",
    "linsvm_predict=linsvm.predict(X_test) \n",
    "print(\"accuracy Score (training) for Linear SVM Classifier:{0:6f}\".format(linsvm.score(X_test,y_test))) \n",
    "print(\"Confusion Matrix for Linear SVM Classifier:\") \n",
    "print(confusion_matrix(y_test,linsvm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060735e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for SVM Classifier:0.394103\n",
      "Confusion Matrix for SVM Classifier:\n",
      "[[ 5231 10566]\n",
      " [ 1249  2454]]\n"
     ]
    }
   ],
   "source": [
    "#Construct Support Vector Machine Model\n",
    "from sklearn.svm import SVC \n",
    "svm = SVC(max_iter=500) \n",
    "svm.fit(X_train, y_train) \n",
    "svm_predict=svm.predict(X_test) \n",
    "print(\"accuracy Score (training) for SVM Classifier:{0:6f}\".format(svm.score(X_test,y_test))) \n",
    "print(\"Confusion Matrix for SVM Classifier:\") \n",
    "print(confusion_matrix(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e688426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for Boosting:0.920308\n",
      "Confusion Matrix for boosting:\n",
      "[[15622   175]\n",
      " [ 1379  2324]]\n",
      "{'n_estimators': 20, 'learning_rate': 0.1}\n",
      "accuracy Score (training) after hypertuning for Boosting:0.895949\n",
      "Confusion Matrix after hypertuning for Boosting:\n",
      "[[15783    14]\n",
      " [ 2015  1688]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     15797\n",
      "           1       0.99      0.46      0.62      3703\n",
      "\n",
      "    accuracy                           0.90     19500\n",
      "   macro avg       0.94      0.73      0.78     19500\n",
      "weighted avg       0.91      0.90      0.88     19500\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.94134938 0.93192231 0.93499847 0.94270752 0.93088929 0.93749668\n",
      " 0.93822168 0.93283042 0.9329906  0.9379878 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Boosting:  0.9361394155006826\n"
     ]
    }
   ],
   "source": [
    "#Construct Gradient Boosting model\n",
    "\n",
    "search_grid={'n_estimators':[5,10,20],'learning_rate':[0.01,.1]}\n",
    "abc =GradientBoostingClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "abc_predict=abc.predict(X_test)\n",
    "print(\"accuracy Score (training) for Boosting:{0:6f}\".format(abc.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for boosting:\")\n",
    "print(confusion_matrix(y_test,abc_predict))\n",
    "abc_random = RandomizedSearchCV(abc,search_grid,n_iter=15)\n",
    "abc_random.fit(X_train, y_train)\n",
    "grid_parm_abc=abc_random.best_params_\n",
    "print(grid_parm_abc)\n",
    "abc= GradientBoostingClassifier(**grid_parm_abc)\n",
    "abc.fit(X_train,y_train)\n",
    "abc_predict = abc.predict(X_test)\n",
    "print(\"accuracy Score (training) after hypertuning for Boosting:{0:6f}\".format(abc.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for Boosting:\")\n",
    "print(confusion_matrix(y_test,abc_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,abc_predict))\n",
    "abc_cv_score = cross_val_score(abc, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(abc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Boosting: \",abc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "967207b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________\n",
      "Ensemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\n",
      "\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [6]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.69899378]\n",
      "    fold  1:  [0.69676897]\n",
      "    fold  2:  [0.70121859]\n",
      "    fold  3:  [0.70145631]\n",
      "    ----\n",
      "    MEAN:     [0.69960941] + [0.00190050]\n",
      "    FULL:     [0.69960939]\n",
      "\n",
      "model  1:     [MLPClassifier]\n",
      "    fold  0:  [0.87647267]\n",
      "    fold  1:  [0.79900895]\n",
      "    fold  2:  [0.86934318]\n",
      "    fold  3:  [0.85998180]\n",
      "    ----\n",
      "    MEAN:     [0.85120165] + [0.03069572]\n",
      "    FULL:     [0.85120154]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.66668352]\n",
      "    fold  1:  [0.66668352]\n",
      "    fold  2:  [0.66663296]\n",
      "    fold  3:  [0.66666667]\n",
      "    ----\n",
      "    MEAN:     [0.66666667] + [0.00002064]\n",
      "    FULL:     [0.66666667]\n",
      "\n",
      "model  3:     [LinearSVC]\n",
      "    fold  0:  [0.66890833]\n",
      "    fold  1:  [0.67937503]\n",
      "    fold  2:  [0.56894372]\n",
      "    fold  3:  [0.68062298]\n",
      "    ----\n",
      "    MEAN:     [0.64946251] + [0.04670960]\n",
      "    FULL:     [0.64946212]\n",
      "\n",
      "model  4:     [RandomForestClassifier]\n",
      "    fold  0:  [0.92248572]\n",
      "    fold  1:  [0.92021035]\n",
      "    fold  2:  [0.92157557]\n",
      "    fold  3:  [0.92359426]\n",
      "    ----\n",
      "    MEAN:     [0.92196647] + [0.00124057]\n",
      "    FULL:     [0.92196645]\n",
      "\n",
      "model  5:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.89932750]\n",
      "    fold  1:  [0.89735551]\n",
      "    fold  2:  [0.90013652]\n",
      "    fold  3:  [0.89937298]\n",
      "    ----\n",
      "    MEAN:     [0.89904813] + [0.00102873]\n",
      "    FULL:     [0.89904812]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"___________________________________________________________________________________________\\nEnsemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\\n\")\n",
    "\n",
    "models = [ KNeighborsClassifier(), MLPClassifier(), SVC(), LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier() ]\n",
    "      \n",
    "S_Train, S_Test = stacking(models,                   \n",
    "                           X_res, y_res, X_test,   \n",
    "                           regression=False, \n",
    "     \n",
    "                           mode='oof_pred_bag', \n",
    "       \n",
    "                           needs_proba=False,\n",
    "         \n",
    "                           save_dir=None, \n",
    "            \n",
    "                           metric=accuracy_score, \n",
    "    \n",
    "                           n_folds=4, \n",
    "                 \n",
    "                           stratified=True,\n",
    "            \n",
    "                           shuffle=True,  \n",
    "            \n",
    "                           random_state=0,    \n",
    "         \n",
    "                           verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2499981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [1.00000000]\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df01cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [0.99984615]\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09486d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [1.00000000]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "413a2585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.034332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.034332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.034332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.034332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.034332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.965668  0.034332\n",
       "1  0.965668  0.034332\n",
       "2  0.965668  0.034332\n",
       "3  0.965668  0.034332\n",
       "4  0.965668  0.034332"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Prediction Probability for the predicted class as a dataframe\n",
    "pred_Probability =pd.DataFrame(model.predict_proba(S_Test))\n",
    "\n",
    "pred_Probability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "737b5331",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (19500) does not match length of index (173836)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m sub\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      3\u001b[0m sub [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuoteNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuoteNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m sub [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuoteConversion_Flag\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m      6\u001b[0m sub\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massgn3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4535\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (19500) does not match length of index (173836)"
     ]
    }
   ],
   "source": [
    "# Create submission for Kaggle\n",
    "sub= pd.DataFrame()\n",
    "sub [\"QuoteNumber\"]= test_data[\"QuoteNumber\"]\n",
    "sub [\"QuoteConversion_Flag\"] = y_pred\n",
    "\n",
    "sub.to_csv('assgn3.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0722c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
